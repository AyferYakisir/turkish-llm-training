# turkish-LLM-from-scratch ğŸ§ ğŸ‡¹ğŸ‡·

Bu proje, **sÄ±fÄ±rdan TÃ¼rkÃ§e bir LLM (Large Language Model)** geliÅŸtirme sÃ¼recini adÄ±m adÄ±m belgelemektedir. AmaÃ§; tokenizer'dan embedding'e, model mimarisinden eÄŸitime kadar tÃ¼m sÃ¼reci elle inÅŸa ederek dil modeli mimarisini derinlemesine anlamaktÄ±r.

ğŸ“Œ **Durum:** GeliÅŸtirme aÅŸamasÄ±nda (aktif olarak gÃ¼ncelleniyor)

---

## ğŸ” AmaÃ§

- TÃ¼rkÃ§e metinlerle Ã§alÄ±ÅŸan, kendi kelime daÄŸarcÄ±ÄŸÄ±na sahip bir LLM oluÅŸturmak
- Tokenizasyon, kelime-ID eÅŸlemeleri, detokenizasyon gibi temel adÄ±mlarÄ± Ã¶ÄŸrenmek
- EÄŸitim verileriyle Ã§alÄ±ÅŸarak sÄ±fÄ±rdan embedding ve model katmanlarÄ± inÅŸa etmek
- EÄŸitilebilir basit bir dil modeli mimarisi (Ã¶rneÄŸin: mini-Transformer) kurmak

---

## ğŸ“ Åu Ana Kadar YapÄ±lanlar

| Dosya                  | AÃ§Ä±klama                                                                 |
|------------------------|--------------------------------------------------------------------------|
| `tokenKodlama_basic.py`   | BoÅŸluklara gÃ¶re basit tokenizasyon                                      |
| `sozlukleTokenize.py`     | Ã–n tanÄ±mlÄ± bir sÃ¶zlÃ¼k ile kelimeleri IDâ€™lere Ã§eviren tokenizer          |
| `idTokenize.py`           | Token IDâ€™lerini tekrar metne Ã§eviren (detokenization) fonksiyonu        |
| `gpt2_tokenize.py`        | GPT-2 modelinin tokenizerâ€™Ä± (tiktoken) ile Ã¶rnek tokenizasyon ve Ã§Ã¶zÃ¼mleme |




---

## ğŸ“Œ Not

Bu proje ÅŸu anda aktif geliÅŸtirilmektedir ve deneysel niteliktedir. Kodlar sade ve anlaÅŸÄ±lÄ±r tutulmaya Ã§alÄ±ÅŸÄ±lmaktadÄ±r.

> - Ä°lerledikÃ§e tÃ¼m geliÅŸmeler bu repoya commit'lenerek eklenecektir.

---
